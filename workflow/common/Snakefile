rule chrom_sizes_human:
    input:
        fasta = config['fasta']
    threads: 1
    resources:
        mem_gb = 4
    output:
        chrom_sizes = config['chrom_sizes']
    shell:
        "faidx {input.fasta} -i chromsizes > {output.chrom_sizes}"


rule wg_utr_fix:
    input:
        gtf = config['gtf_raw']
    threads: 1
    resources:
        mem_gb = 16
    output:
        gtf = config['gtf']
    shell:
        "gencode_utr_fix --input_gtf {input.gtf} --output_gtf {output.gtf}"


rule bam_index:
    input:
        bam = '{bam_path}.bam'
    threads: 1
    resources:
        mem_gb = 4
    output:
        bai = '{bam_path}.bam.bai'
    shell:
        "samtools index {input.bam}"


rule bam_read_count:
    input:
        bam = config['lr']['bam']
    output:
        txt = config['lr']['read_counts']
    params:
        filters = ''
        # filters = '-F 4 -F 256 -F 2048 -q 10'
    threads: 1
    resources:
        mem_gb = 4
    shell:
        "samtools view {params.filters} -c {input.bam} > {output.txt}"

# rule bam_read_count_stats:
#     input:
#         counts = expand(config['lr']['read_counts'], encode_id=df_lr.index),
#         mapping = 'lr_bulk/file_to_hr.tsv',
#         read_annot_counts = 'configs/human_post_talon_read_count.tsv'
#     threads: 1
#     resources:
#         mem_gb = 4
#     output:
#         table = 'reports/tables/read_numbers.csv'
#     script:
#         "./read_counts_stats.ipynb"


rule merge_bams:
    input:
        expand(config['lr']['bam'] + '.bai', encode_id=df_lr.index),
        bams = expand(config['lr']['bam'], encode_id=df_lr.index)
    output:
        bam = config['lr']['merged_bam']
    threads: 16
    resources:
        mem_gb = 64
    run:
        import os
        tmpdir = f'{resources.tmpdir}/mcelik_merge_bams'

        if os.path.exists(tmpdir):
            shell('rm -rf {tmpdir}')
        os.mkdir(tmpdir)

        bams_txt = f'{tmpdir}/batches.txt'

        with open(bams_txt, 'w') as f:
            for line in input.bams:
                f.write(line + '\n')

        shell(f"samtools merge - -b {bams_txt} --no-PG -@ {threads} \
        | samtools sort -@ {threads} -T {tmpdir} \
        | samtools view -bS > {output.bam}")

        shell(f'rm -rf {tmpdir}')
        shell("samtools index -@ {threads} {output.bam}")


rule gencode_cds_start_end:
    input:
        gtf = config['gtf']
    threads: 1
    resources:
        mem_gb = 16
    output:
        bed = config['gencode']['cds']
    script:
        "./extract_cds.py"


rule liftover_fantom:
    input:
        bed = config['fantom']['hg19']
    threads: 1
    resources:
        mem_gb = 16
    log: 'logs/fantom/liftover.log'
    output:
        bed = config['fantom']['hg38']
    script:
        "./liftover_fantom.py"


rule all_common:
    input:
        rules.liftover_fantom.output,

        # rules.wg_utr_fix.output,
        # rules.gencode_cds_start_end.output

        # config['lr']['merged_bam'],
        # expand(config['lr']['read_counts'], encode_id=df_lr.index),

        # expand(config['lr']['bam'] + '.bai', encode_id=df_lr.index),
        expand(config['pas']['bam'] + '.bai', encode_id=df_pas.index),

        # rules.bam_read_count_stats.output
